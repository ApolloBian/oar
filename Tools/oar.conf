# This file must have the bash variable assignment syntax
# $Id$

#########################
# General configuration #
###############################################################################
#
# Database type ("mysql" or "Pg")
DB_TYPE="mysql"

# DataBase hostname
DB_HOSTNAME="localhost"

# Database base name
DB_BASE_NAME="oar"

# DataBase user name
DB_BASE_LOGIN="oar"

# DataBase user password
DB_BASE_PASSWD="oar"

# DataBase read only user name
#DB_BASE_LOGIN_RO="oar_ro"

# DataBase read only user password
#DB_BASE_PASSWD_RO="oar_ro"

# OAR server hostname
SERVER_HOSTNAME="localhost"

# OAR server port
SERVER_PORT="6666"

# when the user does not specify a -l option then oar use this
OARSUB_DEFAULT_RESOURCES="/resource_id=1"

# OAR log level: 3(debug+warnings+errors), 2(warnings+errors), 1(errors)
LOG_LEVEL="2"

# If you want to debug oarexec on nodes then affect 1 (only effective if DETACH_JOB_FROM_SERVER = 1)
OAREXEC_DEBUG_MODE="0"

# oarexec default temporary directory
# This value MUST be the same in all oar.conf on all nodes of the cluster
#OAR_TMP_DIRECTORY="/tmp/oar_runtime"

# OAR log file
LOG_FILE="/var/log/oar.log"

# OAR Allowed networks
# Networks or hosts allowed to submit jobs to OAR and compute nodes may be specified here
ALLOWED_NETWORKS="127.0.0.1/32 0.0.0.0/0"

# Specify where we are connected with a job of the deploy type
DEPLOY_HOSTNAME="127.0.0.1"

# Specify where we are connected with a job of the cosystem type
COSYSTEM_HOSTNAME="127.0.0.1"

# Specify the database field to use to fill the file on the first node of the
# job in $OAR_NODE_FILE (default is 'network_address'). Only resources with
# type=default are displayed in this file.
#NODE_FILE_DB_FIELD="network_address"

# If you want to free a process per job on the server you can change this tag
#into 1 (you must enable all nodes to connect to SERVER_PORT on the SERVER_HOSTNAME)
DETACH_JOB_FROM_SERVER="0"

# Command to use to connect to other nodes (default is "ssh" in the PATH)
#OPENSSH_CMD="/usr/bin/ssh"

# If you have installed taktuk and want to use it to manage remote
# admnistration commands then give the full command path
# (with your options except "-m" and "-o").
# You don t also have to give any taktuk command.
#TAKTUK_CMD="/usr/bin/taktuk -s"

###############################################################################

########################################################################
# Pingchecker options:                                                 #
# How to check if the nodes have a good health or not. This choice is  #
# directly linked to the Suspected state of the resources.             #
# By default OAR uses only "ping". it requests no configuration but it #
# is not accurate about the state of the nodes and it is slow          #
###############################################################################
#
# Set the frequency for checking Alive and Suspected resources (0 means never)
FINAUD_FREQUENCY="300"

# Set time after which Suspected resources become Dead (default is 0 and it
# means never) 
#DEAD_SWITCH_TIME="600"


# Uncomment only one of the following PINGCHECKER configuration

# sentinelle.pl
# If you want to use sentinelle.pl then you must use this tag.
# (sentinelle.pl is like a "for" of ssh but it adds timeout and window to 
# avoid overloading the server)
# (sentinelle.pl is provided with OAR in the install directory)
#PINGCHECKER_SENTINELLE_SCRIPT_COMMAND="/usr/lib/oar/sentinelle.pl -t 5 -w 20"

# Taktuk
# taktuk may be used to check aliveness of nodes.
# Give the arguments of the taktuk command WITHOUT format outputs
# (DO NOT use "-o" option).
# See TAKTUK_CMD tag in this file to specify the path of the taktuk command
#PINGCHECKER_TAKTUK_ARG_COMMAND="-t 3 broadcast exec [ true ]"
#PINGCHECKER_TAKTUK_ARG_COMMAND="-t 3 broadcast exec [ /path/on/nodes/to/my/check/script.sh ]"

# fping
# fping may be used instead of ping to check aliveness of nodes.
# uncomment next line to use fping. Give the complete command path.
#PINGCHECKER_FPING_COMMAND="/usr/bin/fping -q"

# nmap
# nmap may be used instead of ping to check aliveness of nodes.
# uncomment next line to use nmap. Give the complete command path.
# It will test to connect on the ssh port (22)
#PINGCHECKER_NMAP_COMMAND="/usr/bin/nmap -p 22 -n -T5"

# GENERIC command
# a specific script may be used instead of ping to check aliveness of nodes.
# uncomment next line and give the complete command path and its arguments.
# The script must return bad nodes on STDERR (1 line for a bad node and it must
# have exactly the same name that OAR has given in argument of the command)
#PINGCHECKER_GENERIC_COMMAND="/path/to/command arg1 arg2"

###############################################################################

######################
# Mail configuration #
###############################################################################
#
# OAR information may be notified by email to the administror
# set accordingly to your configuration and uncomment the next lines to
# activate the feature.
# (If this tag is right configured then users can use "--notify" option of oarsub
# to receive mails about their jobs)
#MAIL_SMTP_SERVER="smtp.serveur.com"

# You can specify several recipients with a comma between each email address
#MAIL_RECIPIENT="user@domain.com"
#MAIL_SENDER="oar@domain.com"

###############################################################################

###########
# Scripts #
###############################################################################
#
# Set the timeout for the prologue and epilogue execution on computing nodes
#PROLOGUE_EPILOGUE_TIMEOUT="60"

# Files to execute before and after each job on the first computing node
# (by default nothing is executed)
#PROLOGUE_EXEC_FILE="/path/to/prog"
#EPILOGUE_EXEC_FILE="/path/to/prog"

# Set the timeout for the prologue and epilogue execution on the OAR server
#SERVER_PROLOGUE_EPILOGUE_TIMEOUT="60"

# Files to execute before and after each job on the OAR server (by default nothing is executed)
#SERVER_PROLOGUE_EXEC_FILE="/path/to/prog"
#SERVER_EPILOGUE_EXEC_FILE="/path/to/prog"

########################
# Scheduler parameters #
###############################################################################
#
# Maximum of seconds used by a scheduler
SCHEDULER_TIMEOUT="10"

# Time to add between each jobs (for example: time for administration tasks or
# time to let computers to reboot)
SCHEDULER_JOB_SECURITY_TIME="1"

# Minimum time in seconds that can be considered like a hole where a job could
# be scheduled in (if you have performance problems, you can try to increase
# this)
SCHEDULER_GANTT_HOLE_MINIMUM_TIME="300"

# You can add an order preference on resources assigned by the
# system(SQL ORDER syntax)
SCHEDULER_RESOURCE_ORDER="suspended_jobs ASC, switch ASC, network_address DESC, resource_id ASC"

# You can specify a type of resources that will be always assigned for each job
# (for exemple: enable all jobs to be able to log on the cluster frontales)
# For more information, see the FAQ
#SCHEDULER_RESOURCES_ALWAYS_ASSIGNED_TYPE="frontal"

# This says to the scheduler to treate resources of these types, where there is
# a suspended job, like free ones. So some other jobs can be scheduled on these
# resources. (list resource types separate with spaces; Default value is
# nothing so no other job can be scheduled on suspended job resources)
#SCHEDULER_AVAILABLE_SUSPENDED_RESOURCE_TYPE="default licence VLAN"
SCHEDULER_AVAILABLE_SUSPENDED_RESOURCE_TYPE="default"

# Time to wait when a reservation has not got all resources that it has reserved
# (some resources could have become Suspected or Absent since the job submission)
# before to launch the job on the remaining resources (default is 300s)
#RESERVATION_WAITING_RESOURCES_TIMEOUT="300"

# Set the granularity of the OAR accounting feature (in seconds)
# Used by the oaraccounting command and the oar_sched_gantt_with_timesharing_and_fairsharing
# to calculate the timesharing policy
# Default is 1 day (86400s)
#ACCOUNTING_WINDOW="86400"

###############################################################################

###########################################################################
# If you want to manage starting and stopping node feature. OAR gives you #
# this API:                                                               #
###############################################################################
#
# When OAR scheduler wants some nodes to wake up then it launches this command
# with arguments : number_of_nodes_to_wake_up list_of_nodes(the scheduler looks
# at the cm_availability field in resources table to know if the node
# will be started for enough time)
#SCHEDULER_NODE_MANAGER_WAKE_UP_CMD="/path/to/the/command with your args"

# When OAR considers that some nodes can be shut down, it launches this command with
# the node list in arguments
#SCHEDULER_NODE_MANAGER_SLEEP_CMD="/path/to/the/command args"

# Parameters for the scheduler to decide when a node is idle.
# Number of seconds since the last job was terminated on nodes
#SCHEDULER_NODE_MANAGER_IDLE_TIME="600"

# Parameters for the scheduler to decide if a node will have enough time to sleep.
# Number of seconds before the next job
#SCHEDULER_NODE_MANAGER_SLEEP_TIME="600"

################################################################################

##############################
# Suspend/Resume job feature #
###############################################################################
#
# Name of the perl script that manages suspend/resume. You have to install your
# script in $OARDIR and give only the name of the file without the entire path.
# (default is suspend_resume_manager.pl)
#SUSPEND_RESUME_FILE="suspend_resume_manager.pl"

# Files to execute just after a job was suspended and just before a job was resumed
#JUST_AFTER_SUSPEND_EXEC_FILE="/path/to/prog"
#JUST_BEFORE_RESUME_EXEC_FILE="/path/to/prog"

# Timeout for the two previous scripts
#SUSPEND_RESUME_SCRIPT_TIMEOUT="60"

###############################################################################

##################
# CPUSET feature #
###############################################################################
# Indicate the name of the database field that contains the cpu number of the node.
# If this option is set then users must use oarsh instead of ssh to walk on
# each nodes that they have reserved via oarsub.
# Look at Tools/oarsh/README
# (if defined, this otion turn on the cpuset feature in OAR)
#CPUSET_RESOURCE_PROPERTY_DB_FIELD="cpuset"

# Name of the perl script that manages cpuset. You have to install your script
# in $OARDIR and give only the name of the file without the entire path.
# (default is cpuset_manager.pl which handles the linux kernel cpuset)
#CPUSET_FILE="cpuset_manager.pl"

###############################################################################

#########
# OARSH #
###############################################################################
#
# This variable must be set to enable the use of oarsh from a frontale node
# Otherwise you must not set this variable if you are not on a frontale
#OARSH_OARSTAT_CMD="/usr/bin/oarstat"

# The following variable adds options to ssh (or OPENSSH_CMD if configured).
# If one option is not handled by your ssh version just remove it BUT be
# careful because these options are there for security reasons
OARSH_OPENSSH_DEFAULT_OPTIONS="-oProxyCommand=none -oPermitLocalCommand=no"

###############################################################################


#DESKTOP_COMPUTING_ALLOW_CREATE_NODE="0"
#DESKTOP_COMPUTING_EXPIRY="300"
#STAGEOUT_DIR="/var/lib/oar/stageouts/"
#STAGEIN_DIR="/var/lib/oar/stageins"
#STAGEIN_CACHE_EXPIRY="144"

