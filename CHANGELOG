OAR CHANGELOG
=============

version 2.0.2:
--------------

  - add warnings and exit code to oarnodesetting when there is a bad node name
    or resource number
  - change package version
  - change default behaviour for the cpuset_manager.pl (more portable)
  - enable a user to use the same ssh key for several jobs (at his own risk!)
  - add node hostnames in oarstat -f
  - add --accounting and -u options in oarstat
  - bug fix on index fields in the database (syncro): bug 2020
  - bug fix about server pro/epilogue: bug 2022
  - change the default output of oarstat. Now it is usable: bug 1875
  - remove keys in authorized_keys of oar (on the nodes) that do not
    correspond to an active cpuset (clean after a reboot)
  - reread oar.conf after each database connection tries
  - add support for X11 forwarding in oarsub -I and -C
  - debug mysql initialization script in debian package
  - add a variable in oarsh for the default options of ssh to use
    (more useful to change if the ssh version installed does not
    handle one of these options)
  - read oar.conf in oarsh (so admin can more easily change options in this
    script)
  - add support for X11 forwarding via oarsh
  - change variable for oarsh: OARSH_JOB_ID --> OAR_JOB_ID

version 2.0.0++ enhanced:
-------------------------

    - Now, with the ability to declare any type of resources like licences, VLAN, IP range, computing resources must have the type *default* and a network_address not null.
    - Possibility to declare associated resources like licences, IP ranges, ... and to reserve them like others.
    - Now you can connect to your jobs (not only for reservations).
    - Add "cosystem" job type (execute and do nothing for these jobs).
    - New scheduler : "oar_sched_gantt_with_timesharing". You can specify jobs with the type "timesharing" that indicates that this scheduler can launch more than 1 job on a resource at a time. It is possible to restrict this feature with words "user and name". For example, '-t timesharing=user,name' indicates that only a job from the same user with the same name can be launched in the same time than it.
    - Add PostGresSQL support. So there is a choice to make between MySQL and PostgresSQL. 
    - New approach for the scheduling : administrators have to insert into the databases descriptions about resources and not nodes. Resources have a network address (physical node) and properties. For example, if you have dual-processor, then you can create 2 different resources with the same natwork address but with 2 different processor names.
    - The scheduler can now handle resource properties in a hierarchical manner. Thus, for example, you can do "oarsub -l /switch=1/cpu=5" which submit a job on 5 processors on the same switch.
    - Add a signal handler in oarexec and propagate this signal to the user process.
    - Support '#OAR -p ...' options in user script.
    - Add in oar.conf:
        * DB_BASE_PASSWD_RO : for security issues, it is possible to execute request with parts specified by users with a read only account (like "-p" option).
        * OARSUB_DEFAULT_RESOURCES : when nothing is specified with the oarsub command then OAR takes this default resource description.
        * OAREXEC_DEBUG_MODE : turn on or off debug mode in oarexec (create /tmp/oar/oar.log on nodes).
        * FINAUD_FREQUENCY : indicates the frequency when OAR launchs Finaud (search dead nodes).
        * SCHEDULER_TIMEOUT : indicates to the scheduler the amount of time after what it must end itself.
        * SCHEDULER_JOB_SECURITY_TIME : time between each job.
        * DEAD_SWITCH_TIME : after this time Absent and Suspected resources are turned on the Dead state.
        * PROLOGUE_EPILOGUE_TIMEOUT : the possibility to specify a different timeout for prologue and epilogue (PROLOGUE_EPILOGUE_TIMEOUT).
        * PROLOGUE_EXEC_FILE : you can specify the path of the prologue script executed on nodes.
        * EPILOGUE_EXEC_FILE : you can specify the path of the epilogue script executed on nodes.
        * GENERIC_COMMAND : a specific script may be used instead of ping to check aliveness of nodes. The script must return bad nodes on STDERR (1 line for a bad node and it must have exactly the same name that OAR has given in argument of the command).
        * JOBDEL_SOFTWALLTIME : time after a normal frag that the system waits to retry to frag the job.
        * JOBDEL_WALLTIME : time after a normal frag that the system waits before to delete the job arbitrary and suspects nodes.
        * LOG_FILE : specify the path of OAR log file (default : /var/log/oar.log).
        
    - Add wait() in pingchecker to avoid zombies.
    - Better code modularization.
    - Remove node install part to launch jobs. So it is easier to upgrade from one version to an other (oarnodesetting must already be installed on each nodes if we want to use it).
    - Users can specify a method to be notified (mail or script).
    - Add cpuset support
    - Add prologue and epilogue script to be executed on the OAR server before and after launching a job.
    - Add dependancy support between jobs ("-a" option in oarsub).
    - In oarsub you can specify the launching directory ("-d" option).
    - In oarsub you can specify a job name ("-n" option).
    - In oarsub you can specify stdout and stderr file names.
    - User can resubmit a job (option "--resubmit" in oarsub).
    - It is possible to specify a read only database account and it will be used to evaluate SQL properties given by the user with the oarsub command (more scecure).
    - Add possibility to order assigned resources with their properties by the scheduler. So you can privilege some resources than others (SCHEDULER_RESOURCE_ORDER tag in oar.conf file)
    - a command can be specified to switch off idle nodes (SCHEDULER_NODE_MANAGER_SLEEP_CMD, SCHEDULER_NODE_MANAGER_IDLE_TIME, SCHEDULER_NODE_MANAGER_SLEEP_TIME in oar.conf)
    - a command can be specified to switch on nodes in the Absent state according to the resource property *cm_availability* in the table resources_ (SCHEDULER_NODE_MANAGER_WAKE_UP_CMD in oar.conf).
    - if a job goes in Error state and this is not its fault then OAR will resubmit this one.

version 1.6.1:
--------------

    - initialise the "ganttJobsPrediction" table with a right reference date (1970-01-01 00:00:01)
    - oarsub has the "-k, --checkpoint" option. It specifies the number of seconds before job walltime to send a SIGUSR2 on it.
    - You can see the list of events for jobs with -f option in oarstat
    - oardel can now send SIGUSR2 to the oarexec of a job (-c option)
    - oardel can now delete several jobs
    - Add a signal handler in oarexec and propagate this signal to the user process
    - Support '#OAR -p ...' options in user script
    - Add in oar.conf the possibility to specify a different timeout for prologue and epilogue (PROLOGUE_EPILOGUE_TIMEOUT)
    - when a connection to the DB fails, OAR retrie 5 times
    - handle the EXTERMINATE_JOB event and suspect all nodes if possible
    - add job state log table
    - add node properties log table
    - add possibility to use sentinelle.rb script in the ping_checker module
    - add a GRID5000 specific scheduler which implements specific policy
      (oar_sched_gant_g5k)
    - add -s option to oarnodes command --> show only state of nodes
    - add -l option to oarnodes command --> show only the node list
    - root can now delete any jobs in the same way the oar user could
    - change a few oardel messages
    - limit the commands (with arguments) specified by users::

        regular expression : [\w\s\/\.\-]*

    - change oaremovenode command to oarremovenode
    - enhance job error management
    - enhance suspicious nodes detection
    - fix bugs about accounting

version 1.6:
------------

    - debug reservation jobs (if the job has not the right number of requested nodes then it will wait for a delay. Once expired, the job will be launched on the nodes available).
    - add a cache for visualization of the gantt scheme (add two gantt table for the visu)
    - add an event log mechanism. It permits to know all decisions and events occuring in OAR with regards to jobs.
    - detection of errors (they can be traced via event_log table):
        * job working directory does not exist on the node
        * output files cannot be created
    - add deploy scheduler awareness (schedule on non deploy nodes firstly)
    - possibility to change property value via oarnodesetting command (-p option)
    - add the command "oaremovenode" that allows to delete a node of the database definitely
    - bug fix : now oarsub can use the user's script even if the oar user cannot
    - now, you can use special value "all" in oarsub ("nodes" resource). It gives all free nodes corresponding to the weight and properties specified.
    - debug Gantt visualization
    - add the possibility to test nodes via nmap
    - add accounting features (accounting table)
    - change nodeState_log table scheme to increase rapidity

