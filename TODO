========
OAR TODO
========

.. contents:: Table des matières

-------------
Documentation
-------------
  Doc plus ouverte.
  Les personnes qui sont intéressées pour contribuer à la documentation de OAR
  sont les bienvenue (ajout de sections, correction de l'anglais, ...).
  
  Avis aux amatrices et amateurs ...:

   http://oar.imag.fr/docs/manual.html

-----
Forge
-----
  Il a été décidé d'utiliser la "forge" de l'INRIA pour héberger le projet
  ( http://gforge.inria.fr/projects/oar/ ).
  Techniquement nous allons passer sous le gestionnaire de versions
  *subversion*.

--------
Site web
--------
   Refonte et mise à jour. Elle est déjà en ligne à l'adresse habituelle:

     http://oar.imag.fr/ 

--------------
Scheduling G5K
--------------
  Rappel sur la politique décidée en CP:
  
    - Réservation complète possible dans la journée mais pas plus d'1 heure.
    - Un job interactif ne doit pas dépasser 12h.
    - En pleine journée, on autorise jusqu'à 12h, mais pas plus de 50% de la
      machine.
    - Nuit et journée. La nuit commence à 22h, la journée 7h.
    - Nuit, on a le droit de tout faire.
    - Tout autre job est une exception gérée par le responsable local.

  Question soulevée : Que doit-on faire des jobs demandant 3 jours de walltime,
  qui vont commencer la nuit et continuer le jour?

--------
Epilogue
--------
  Epilogue : robustesse
  2 solutions:
  
   - brutale : on enlève les prologue/epilogue du oarexec et on crée un module
     côté serveur qui les gere. Du coup ca va rajouter de la latence et de la
     complexité dans l'enchainement des états des jobs.
   - souple : on détecte lorsque quelque chose se passe mal (c'est ce qui est
     déjà fait) et on avise.
  
  Dans les 2 cas on a un problème : il se peut que l on détecte un problème
  lors de l épilogue par exemple. Dans ce cas on se dit qu il faut le relancer,
  ca semble logique... Or si les scripts ne sont pas "idempotants" cela peut
  poser de très gros problèmes --> Pas simple!!!

  Pourquoi ne pas faire un prologue/epilogue qui se loggerait sur tous les
  noeuds du job? (détection des pannes plus fine).

CPUSET
------
  Il faut regarder pour utiliser la technique des *cpuset* (qui est présente
  dans les sources du noyau linux depuis les versions 2.6). Dans ce cas il faut
  surcharger le connecteur *ssh* utilisé pour déployer les applications pour
  qu'il oblige les processus à se mettre dans le bon *cpuset*.
  Avec cette technique il sera possible de nettoyer correctement les noeuds et
  de rendre plus robuste les épilogues.

  De plus, il faut regarder comment sont gérés les systèmes équivalents au
  *cpuset* sur solaris, AIX et iris.
  Comment PBS gère le cpuset (et plus largement le confinement des
  applications).

  A noter: un prototype de wrapper existe et a l'air de fonctionner
  correctement. Son nom est *oarsh*. Donc il serait possible d'obliger les
  utilisateurs à utiliser ce wrapper pour les confiner dans le cpuset de leur
  job.

---------
GridPrems
---------
  DrawGantt et Monika Gridprems aware (new DrawGantt et Monika ?)
  Implémentation d'un historique des propriétés des noeuds pour savoir quand un
  noeud était en mode *GridPrems* par exemple.

-------------------------
suspend/resume/checkpoint
-------------------------
  Demander aux personnes du *checkpointing* s'il faut envoyer un signal a tous
  les processus ou seulement a celui de tête??????

  Faire une table de log des états des jobs --> connaissance de plusieurs
  cycles pour les jobs + historique...

------------------------------
Scheduling : nouvelle approche
------------------------------
  **ATTENTION** : Changement complet du système de scheduling.
  
  Dans la version actuelle de OAR, le scheduler attribue des noeuds (d'un
  certain poids) à des jobs.
  L'idée est de considérer des ressources à la place des noeuds. Celles-ci
  possèdent des propriétés (telles que: switch, type de cpu, numéro de CPU,
  numéro de CORE de CPU, quantité de mémoire, ...)
  Donc le scheduler doit assigner des ressources qui correspondront à la
  requête de l'utilisateur à son job.

  Ainsi il serait possible de réaliser des requêtes du type:

    oarsub switch="s2" noeud=10 cpu=1 -p "memory > 256"
  
  Dans cet exemple, nous voulons utiliser 1 CPU sur 10 noeuds différents
  appartenant au switch "s2". De plus les ressources devront posséder une
  mémoire de plus de 256Mo.

  Au niveau de la base de données, nous aurions un schéma du style:

  ========== ======== === ==== ====== ====== ========== ====== ===
  resourceId hostname CPU CORE switch memory besteffort deploy ...
  ========== ======== === ==== ====== ====== ========== ====== ===

Tâches malléables
-----------------
  Nous allons également supporter les tâches malléables (jobs pouvant se lancer
  sur un nombre de ressources non spécifés en dur à la soumission). Donc le
  scheduler pourra décider lui-même le nombre de ressources à attribuer et du
  walltime correspondant (le scheduler change le walltime a la volé en fonction
  du nombre de ressources qu il attribut a la tâche).
  Pour se faire l'utilisateur devra fournir au système une matrice de coût
  dont la première colonne sera par exemple le nombre de ressources et la
  seconde le temps correspondant à l'exécution de la tâche.

---------------------
Dépendance entre jobs
---------------------

  1. Problème de syntaxe de la ligne de commande du oarsub.
  2. Problème de schéma de la base : une nouvelle table stockant les dependances.
   
    ===== ===============
    idJob idJobDependancy
    ===== ===============

  3. Problème de scheduling.

----------
Simulateur
----------
   Le simulateur est en cours d'écriture.
  
   Les 2 principales notions sont:
    
    - temps compressible : le système est en attente de la fin d'un job ou d'
      une soumission. Donc rien ne se passe dans OAR et donc nous avons la
      possibilité d'accélérer le temps jusqu'au prochain événement.
    - temps incompressible : le système fait quelque-chose que l'on ne peut
      pas accélérer. Donc on laisse faire OAR.

   Donc le temps de référence du système ne sera plus celui de la base de
   données mais sera fourni par un autre moyen.

   Ce simulateur nous permettra de valider plus facilement et avec plus
   d'exactitude les ordonnanceurs introduits dans OAR grâce à des jeux
   de tests.

--------
Sécurité
--------
  - clés SSH sur les noeuds (réfléchir aussi à l'authentification par *rhost*)
  - NFS, une image déployée sur un noeud peut tout monter ou restreindre le
    NFS pour certaines IP (prologue/epilogue executés côté serveur)?
  - VLAN?

------------------------------------
Comparaison avec les autres systèmes
------------------------------------
 
------------------
OAR dans la debian
------------------
  Que reste-t-il à faire ?

------------------------
Console d'administration
------------------------
  Notamment il faut faire une commande pour flusher la base (serveur éteind et
  noeuds éteind) = remettre tout d'aplomb...

----------------------------------------------
Rendre la base de données **transactionnelle**
----------------------------------------------
  Celà permettrait d'être plus tolérent aux pannes.

----------------------
Interface avec OpenPBS
----------------------

-----------------
Interface Globus4
-----------------

---------
Publicité
---------
  Pub OAR Orap, wikipedia, site linuxhpc.

----------------------------------------
Stagein/stageout des fichiers de données
----------------------------------------

-----------------------
Tests de non regression
-----------------------

------------------------------------------
Faire les *man* des commandes qui manquent
------------------------------------------

